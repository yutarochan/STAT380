---
title: "Career Village - Exploratory Data Anaysis"
author: "Yuya Jeremy Ong & Tomoki Takasawa"
date: 'Due: 03/02/2019'
output: html_notebook
---

```{r Front Matter, include=FALSE}
rm(list = ls())

# Packages
library(mdsr)
library(dplyr)
library(tidyr)
library(readr)
library(ggplot2)
library(scales)
library(tokenizers)
library(ngram)
library(text2vec)
library(textmineR)
library(wordcloud)
library(tm)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(randomForest)
library(rpart)

# [Inputs and Source Data]
# CareerVillage Datasets
# Source: https://www.kaggle.com/c/data-science-for-good-careervillage/discussion/88316#latest-521963
answers <- read_csv("../data/careervillage/answers.csv")
comments <- read_csv("../data/careervillage/comments.csv")
emails <- read_csv("../data/careervillage/emails.csv")
group_memberships <- read_csv("../data/careervillage/group_memberships.csv")
groups <- read_csv("../data/careervillage/groups.csv")
matches <- read_csv("../data/careervillage/matches.csv")
professionals <- read_csv("../data/careervillage/professionals.csv")
questions <- read_csv("../data/careervillage/questions.csv")
questions_score <- read_csv("../data/careervillage/question_scores.csv")
school_memberships <- read_csv("../data/careervillage/school_memberships.csv")
students <- read_csv("../data/careervillage/students.csv")
tag_questions <- read_csv("../data/careervillage/tag_questions.csv")
tag_users <- read_csv("../data/careervillage/tag_users.csv")
tags <- read_csv("../data/careervillage/tags.csv")

# National Center for Educational Statistics - Estimated Annual Salary of Elementary and Secondary School Teachers by State (2015 - 2016)
# Source: https://nces.ed.gov/programs/digest/d17/tables/dt17_211.60.asp
salaries <- read_csv("../data/tabn211.60.csv")

# [User Defined Functions & Constants]
# Tags of Interest
interest <- c('teaching', 'teacher', 'education', 'high school', 'school')

# extractTags: User Defined Function to extract the vector of Ids for the interested tag given vector of tag Ids and table for the tags*
extractTags <- function(tagTable, interest) {
  tagsOfInterest <- tagTable %>% 
    filter(tags_tag_name %in% interest) %>% 
    pull(tags_tag_id)
  return(tagsOfInterest)
}

# extractStudentsWithInterest: User Defined Function to create a dataframe for students who posted one or more questions with tags of interests.*
extractStudentsWithInterest <- function(tagTable, userTagTable, studentsTable, interest) {
  tagsOfInterest <- extractTags(tagTable, interest)
  
  userIds <- userTagTable %>% 
    filter(tag_users_tag_id %in% tagsOfInterest) %>%
    select(tag_users_user_id) %>% 
    pull(tag_users_user_id)
  
  table <- studentsTable %>% 
    filter(students_id %in% userIds) %>%
    drop_na()
  names(table)[names(table) == 'students_id'] <- 'userId'
  return(table)
}

# extractQuestionsOfInterests: User Defined Function to create a dataframe for questions and their rate(score) with tags of interests.*
extractQuestionsOfInterests <- function(tagTable, questionTagTable, questionTable, questionScoreTable, interest) {
  tagsOfInterest <- extractTags(tagTable, interest)
  
  df <- questionTagTable %>% 
    filter(tag_questions_tag_id %in% tagsOfInterest)
  
  for (i in 1:length(interest)){
    df <- df %>%
      mutate('dummy' = ifelse(tag_questions_tag_id %in% tagsOfInterest[i],1,0))
    names(df)[names(df) == 'dummy'] <- interest[i]
  }
  
  df <- aggregate(. ~tag_questions_question_id, data=df, sum, na.rm=TRUE)
  
  questionIdVector <- df %>% 
    pull(tag_questions_question_id)
  
  table <- questionTable %>% filter(questions_id %in% questionIdVector)
  
  df <- df %>% select(-tag_questions_tag_id)
  print(df)
  
  names(df)[names(df) == 'tag_questions_question_id'] <- 'questions_id'
  table <- merge(table, df,by=c("questions_id"))
  
  names(table)[names(table) == 'questions_id'] <- 'id'
  total <- merge(table, questionScoreTable,by=c("id"))
  
  names(total)[names(total) == 'questions_author_id'] <- 'userId'
  return(total)
}
```


## Exploratory Data Analysis
First, we take a look at each of the dataset to get a good overview of what we are working with.

### Student
```{r}
head(students, 5)
count(students)
```

```{r}
# Identify NAs for Student Location
sum(is.na(students$students_location))
```

```{r}
# Preprocess Date Joined
students$students_date_joined <- as.Date(students$students_date_joined)
students$date_num <- as.numeric(students$students_date_joined)

# Setup Date Histogram
bin <- 30
ggplot(students, aes(date_num, ..count..)) +
  geom_histogram(binwidth = bin, colour="white") +
  ggtitle("Students Date Joined") +
  xlab("Date") + 
  ylab("Count")
```

### Group
```{r}
# Peek at Data
head(groups, 5)
count(groups)
unique(groups$groups_group_type)
```

```{r}
# Check Count of Group Type
group_df <- groups %>%
  count(groups$groups_group_type)
group_df <- data.frame(group_df)

group_df[order(group_df$n, decreasing=TRUE), ]
```

```{r}
head(group_memberships, 5)
count(group_memberships)
```

### Group Memberships
```{r}
# Perform a Group by Sum of Membership Groups
group_df <- group_memberships %>%
  count(group_memberships_user_id)
group_df <- data.frame(group_df)

group_df[order(group_df$n, decreasing=TRUE), ]
```

```{r}
# Plot Membership Counts Per Group
barplot(group_df$n, main="Membership Groups", xlab="Groups", ylab="Count")
```

```{r}
# Join with Groups
names(group_memberships)[1] <- "groups_id"
merge(group_memberships, groups)
```

### School Memberships
```{r}
head(school_memberships, 5)
count(school_memberships)
```

```{r}
group_df <- school_memberships %>%
  count(school_memberships$school_memberships_school_id)
group_df <- data.frame(group_df)

group_df[order(group_df$n, decreasing=TRUE), ]
```

### Professionals
```{r}
head(professionals, 5)
count(professionals)
```

```{r}
# Find Number of NAs Per Feature
sum(is.na(professionals$professionals_location))
sum(is.na(professionals$professionals_industry))
sum(is.na(professionals$professionals_headline))
```

```{r}
# Preprocess Date Joined
professionals$professionals_date_joined <- as.Date(professionals$professionals_date_joined)
professionals$date_num <- as.numeric(professionals$professionals_date_joined)

# Setup Date Histogram
bin <- 30
ggplot(professionals, aes(date_num, ..count..)) +
  geom_histogram(binwidth = bin, colour="white") +
  ggtitle("Professionals Date Joined") +
  xlab("Date") + 
  ylab("Count")
```

```{r}
# Student vs Professional Join Date Timing
joint <- rbind(
  data.frame(date_num = students$date_num, user='student', type = "Cont"),
  data.frame(date_num = professionals$date_num, user='prof', type = "Cont")
)

ggplot(joint, aes(date_num, ..count..)) + 
    geom_histogram(data=subset(joint,user == 'student'),fill = "red", alpha = 0.2) +
    geom_histogram(data=subset(joint,user == 'prof'),fill = "blue", alpha = 0.2) +
    ggtitle("Temporal Distribution of Students vs Professionals Sign Up") +
    xlab("Date") + 
    ylab("Count")
```

### Emails
```{r}
head(emails, 5)
count(emails)
```

```{r}
# Category Counts of Emails
group_df <- emails %>%
  count(emails$emails_frequency_level)
group_df <- data.frame(group_df)

group_df[order(group_df$n, decreasing=TRUE), ]
```

```{r}
# Preprocess Date Sent
emails$emails_date_sent <- as.Date(emails$emails_date_sent)
emails$date_num <- as.numeric(emails$emails_date_sent)

# Setup Date Histogram
bin <- 30
ggplot(professionals, aes(date_num, ..count..)) +
  geom_histogram(binwidth = bin, colour="white") +
  ggtitle("Emails Date Sent") +
  xlab("Date") + 
  ylab("Count")
```

### Matches
```{r}
head(matches, 5)
count(matches)
```

### Questions
```{r}
head(questions, 10)
count(questions)

questions <- data.frame(questions)
```

### Question Scores
```{r}
head(questions_score, 5)
count(questions_score)
```

```{r}
# Obtain Score Frequency
group_df <- questions_score%>%
  count(questions_score$score)
group_df <- data.frame(group_df)

group_df[order(group_df$n, decreasing=TRUE), ]
```

```{r}
qplot(group_df$n, geom="histogram", bins=30) +
  ggtitle("Distribution of Question Scores") + 
  xlab("Score") +
  ylab("Count")
```

## Data Extraction and Preprocessing
We perform various preprocessing methods to extract the relevant field of interest for our data analysis in later phases.

We generate a user-centric table of all students who joined CareerVillage along with their location data.
```{r}
usersOfInterests <- extractStudentsWithInterest(tags, tag_users, students, interest)
head(usersOfInterests)
```

We also generate a question-centric table for the list of questions people asked.
```{r}
questionsOfInterests <- extractQuestionsOfInterests(tags, tag_questions, questions, questions_score, interest)
head(questionsOfInterests)
```

We then perform a merge between the two tables as a single table.
```{r}
combinedData <- merge(x = questionsOfInterests, y = usersOfInterests, by = "userId", all.X = TRUE)
names(combinedData)[names(combinedData) == 'high school'] <- 'high'
combinedData
```

## Data Analysis

### Supervised Learning

*examining data by mean and quartile*
```{r}
x <- as.list(as.data.frame(combinedData$score))
lapply(x, mean)
lapply(x, quantile, probs = 1:3/4)
sapply(x, quantile)
```

#### split
```{r}
n <- nrow(combinedData)
test_idx <- sample.int(n, size = round(0.20 * n))
train <- combinedData[-test_idx, ]
test <- combinedData[test_idx, ]
```

#### linear model
```{r}
mod_logit <- glm(score ~ teacher + teaching + high + school + education, data = train, family = "gaussian")
logitProb <- predict(mod_logit, newdata = test, type = "response")
plot(logitProb)
test <- test %>%
  mutate(regression = logitProb)
```


#### random forest
```{r}
mod_forest <- randomForest(score ~ teacher + teaching + high + school + education, data = train, ntree = 100, mtry = 2)
mod_forest <- predict(mod_forest, newdata = test, type = "response")
plot(mod_forest)
test <- test %>%
  mutate(forest = mod_forest)

```

#### simple tree
```{r}
mod_tree <- rpart(score ~ teacher + teaching + high + school + education, data = train)
tree_pred <- predict(mod_tree, newdata = test, type = "vector")
plot(tree_pred)
test <- test %>%
  mutate(tree = tree_pred)
```

### Accuracy Check
```{r}

resultTest <- test %>%
  select(regression, tree, forest, score) %>%
  mutate(regression_diff = (as.double(regression) - score) ** 2,
         tree_diff = (as.double(tree) - score) ** 2,
         forest_diff = (as.double(forest) - score) ** 2)

rmseRegression <- sqrt(mean(resultTest$regression_diff))
rmseTree <- sqrt(mean(resultTest$tree_diff))
rmseForest <- sqrt(mean(resultTest$forest_diff))

rmseRegression
rmseTree
rmseForest

```

### Unsupervised Learning
```{r}
samples = sample(questionsOfInterests, 100, replace=FALSE)

it_data = itoken(samples$questions_body,
       preprocessor = tolower,
       tokenizer = word_tokenizer,
       ids = samples$id,
       progressbar = FALSE,
       na.rm=TRUE)

vocab = create_vocabulary(it_data)

vectorizer = vocab_vectorizer(vocab)
dtm_data = create_dtm(it_data, vectorizer)


# Define Tf-idf Model
tfidf = TfIdf$new()
tfidf_data = fit_transform(dtm_data, tfidf)

vectors = transform(tfidf_data, tfidf)
tf_mat <- TermDocFreq(dtm_data)

tfidf <- t(dtm_data[ , tf_mat$term ]) * tf_mat$idf
tfidf <- t(tfidf)

csim <- tfidf / sqrt(rowSums(tfidf * tfidf))
csim <- csim %*% t(csim)

cdist <- as.dist(1 - csim)
```

### Hierarchical Clustering of Questions
```{r}
hc <- hclust(cdist, method = "average")

clustering <- cutree(hc, 20)

par(cex=0.5)
plot(hc, main = "Hierarchical clustering of Sampled Career Village Questions", ylab = "", xlab = "", yaxt = "n")

rect.hclust(hc, 20, border = "red")
```

```{r}
# Preproces Question Title Data
docs <- Corpus(VectorSource(questionsOfInterests$questions_title))

toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)

# Word Cloud Visualization from Cluster
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)

wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

### Data Visualizations

Teacher Salary vs Student Interest vs Professionals Avaiability Per State

Identify Student Interest Per State
```{r}
# Identify Relative Interest of Students by State
st_interest <- data.frame()
for (st in state.name) {
  res <- dplyr::filter(usersOfInterests, grepl(st, usersOfInterests$students_location))
  st_interest <- rbind(st_interest, res)
}

# Persist Total Count
total_count <- nrow(st_interest)

# Normalize Location Data
Pattern = paste0(paste0(".*\\b(", paste0(state.name, collapse="|")), ")\\b.*")
st_interest$students_location = sub(Pattern, "\\1", st_interest$students_location)

state_count <- st_interest %>%
  group_by(students_location) %>%
  count()

state_count$int_ratio <- state_count$n / total_count
state_count
```

Identify Number of Professionals Per State
```{r}
# Filter Professionals by States
pr_counts <- data.frame()
for (st in state.name) {
  res <- dplyr::filter(professionals, grepl(st, professionals$professionals_location))
  pr_counts <- rbind(pr_counts, res)
}

# Filter by Education
pr_counts <- filter(pr_counts, pr_counts$professionals_industry == "Education")

# Persist Total Count
total_count <- nrow(pr_counts)

# Normalize Location Data
Pattern = paste0(paste0(".*\\b(", paste0(state.name, collapse="|")), ")\\b.*")
pr_counts$professionals_location = sub(Pattern, "\\1", pr_counts$professionals_location)

prof_counts <- pr_counts %>%
  group_by(professionals_location) %>%
  count()

prof_counts
```

Merge with Salary Dataset
```{r}
# Load Salary Dataset
salaries <- read_csv("../data/tabn211.60.csv")
head(salaries)
```

```{r}
# Visualize Relationships Between Two Years
salaries$delta <- salaries$`2016` - salaries$`2015`
ggplot(salaries, aes(x=`2015`, y=`2016`)) +
  geom_point(aes(color=delta)) +
  ggtitle("US States Teacher Salaries 2015 vs 2016") +
  xlab("2015") + 
  ylab("2016")
```

```{r}
# Compute Average Salaries Two Years
salaries$avg <- (salaries$`2016` + salaries$`2015`) / 2
salaries
```

```{r}
# Rename Columns for Consistency
names(salaries)[1] <- "state"
names(state_count)[1] <- "state"
names(prof_counts)[1] <- "state"

names(state_count)[2] <- "st_cnt" 
names(state_count)[3] <- "st_ratio" 

names(prof_counts)[2] <- "pf_cnt"

# Merge Operation
merge_df <- merge(salaries, state_count, by="state", all = TRUE)
merge_df <- merge(merge_df, prof_counts, by="state", all = TRUE)

merge_df
```

```{r}
# Build Visualization
ggplot(merge_df, aes(x=avg, y=st_ratio)) +
  geom_point(aes(color=pf_cnt)) +
  geom_text(label=merge_df$state, size=1.5, nudge_x = 0, nudge_y = 0.005) +
  ggtitle("US States Teacher Salaries vs Student Interest in CV vs Professionals Counts") +
  xlab("Salaries") + 
  ylab("Interest Ratios")
```