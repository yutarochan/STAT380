---
title: "Career Village - Exploratory Data Anaysis"
author: "Yuya Jeremy Ong & Tomoki Takasawa"
date: 'Due: 03/02/2019'
output:
html_notebook: default
---

```{r Front Matter, include=FALSE}
rm(list = ls())

install.packages("text2vec")

# Packages
library(mdsr)
library(dplyr)
library(tidyr)
library(readr)
library(ggplot2)
library(scales)
library(tokenizers)
library(ngram)
library(text2vec)
library(randomForest)
library(rpart)

# Inputs and Source Data
answers <- read_csv("../data/careervillage/answers.csv")
comments <- read_csv("../data/careervillage/comments.csv")
emails <- read_csv("../data/careervillage/emails.csv")
group_memberships <- read_csv("../data/careervillage/group_memberships.csv")
groups <- read_csv("../data/careervillage/groups.csv")
matches <- read_csv("../data/careervillage/matches.csv")
professionals <- read_csv("../data/careervillage/professionals.csv")
questions <- read_csv("../data/careervillage/questions.csv")
questions_score <- read_csv("../data/careervillage/question_scores.csv")
school_memberships <- read_csv("../data/careervillage/school_memberships.csv")
students <- read_csv("../data/careervillage/students.csv")
tag_questions <- read_csv("../data/careervillage/tag_questions.csv")
tag_users <- read_csv("../data/careervillage/tag_users.csv")
tags <- read_csv("../data/careervillage/tags.csv")
```

# Career Village Exploratory Data Analysis

## Individual Dataset Analysis
### Student
```{r}
head(students, 5)
count(students)
```

```{r}
# Identify NAs for Student Location
sum(is.na(students$students_location))
```

```{r}
# Preprocess Date Joined
students$students_date_joined <- as.Date(students$students_date_joined)
students$date_num <- as.numeric(students$students_date_joined)

# Setup Date Histogram
bin <- 30
ggplot(students, aes(date_num, ..count..)) +
  geom_histogram(binwidth = bin, colour="white") +
  ggtitle("Students Date Joined") +
  xlab("Date") + 
  ylab("Count")
```

### Group
```{r}
# Peek at Data
head(groups, 5)
count(groups)
unique(groups$groups_group_type)
```

```{r}
# Check Count of Group Type
group_df <- groups %>%
  count(groups$groups_group_type)
group_df <- data.frame(group_df)

group_df[order(group_df$n, decreasing=TRUE), ]
```

```{r}
head(group_memberships, 5)
count(group_memberships)
```

### Group Memberships
```{r}
# Perform a Group by Sum of Membership Groups
group_df <- group_memberships %>%
  count(group_memberships_user_id)
group_df <- data.frame(group_df)

group_df[order(group_df$n, decreasing=TRUE), ]
```

```{r}
# Plot Membership Counts Per Group
barplot(group_df$n, main="Membership Groups", xlab="Groups", ylab="Count")
```

```{r}
# Join with Groups
names(group_memberships)[1] <- "groups_id"
merge(group_memberships, groups)
```

### School Memberships
```{r}
head(school_memberships, 5)
count(school_memberships)
```

```{r}
group_df <- school_memberships %>%
  count(school_memberships$school_memberships_school_id)
group_df <- data.frame(group_df)

group_df[order(group_df$n, decreasing=TRUE), ]
```

### Professionals
```{r}
head(professionals, 5)
count(professionals)
```

```{r}
# Find Number of NAs Per Feature
sum(is.na(professionals$professionals_location))
sum(is.na(professionals$professionals_industry))
sum(is.na(professionals$professionals_headline))
```

```{r}
# Preprocess Date Joined
professionals$professionals_date_joined <- as.Date(professionals$professionals_date_joined)
professionals$date_num <- as.numeric(professionals$professionals_date_joined)

# Setup Date Histogram
bin <- 30
ggplot(professionals, aes(date_num, ..count..)) +
  geom_histogram(binwidth = bin, colour="white") +
  ggtitle("Professionals Date Joined") +
  xlab("Date") + 
  ylab("Count")
```

### Emails
```{r}
head(emails, 5)
count(emails)
```

```{r}
# Category Counts of Emails
group_df <- emails %>%
  count(emails$emails_frequency_level)
group_df <- data.frame(group_df)

group_df[order(group_df$n, decreasing=TRUE), ]
```

```{r}
# Preprocess Date Sent
emails$emails_date_sent <- as.Date(emails$emails_date_sent)
emails$date_num <- as.numeric(emails$emails_date_sent)

# Setup Date Histogram
bin <- 30
ggplot(professionals, aes(date_num, ..count..)) +
  geom_histogram(binwidth = bin, colour="white") +
  ggtitle("Emails Date Sent") +
  xlab("Date") + 
  ylab("Count")
```

### Matches
```{r}
head(matches, 5)
count(matches)
```

### Questions
```{r}
head(questions, 10)
count(questions)

questions <- data.frame(questions)
```

### Question Scores
```{r}
head(questions_score, 5)
count(questions_score)
```

```{r}
# Obtain Score Frequency
group_df <- questions_score%>%
  count(questions_score$score)
group_df <- data.frame(group_df)

group_df[order(group_df$n, decreasing=TRUE), ]
```

```{r}
qplot(group_df$n, geom="histogram", bins=30) +
  ggtitle("Distribution of Question Scores") + 
  xlab("Score") +
  ylab("Count")
```




### Data Extraction
```{r}
# extractTags: User Defined Function to extract the vector of Ids for the interested tag given vector of tag Ids and table for the tags
extractTags <- function(tagTable, interest) {
  tagsOfInterest <- tagTable %>% 
    filter(tags_tag_name %in% interest) %>% 
    pull(tags_tag_id)
  return(tagsOfInterest)
}

```


```{r}
# extractStudentsWithInterest: User Defined Function to create a dataframe for students who posted one or more questions with tags of interests.
extractStudentsWithInterest <- function(tagTable, userTagTable, studentsTable, interest) {
  tagsOfInterest <- extractTags(tagTable, interest)
  
  userIds <- userTagTable %>% 
    filter(tag_users_tag_id %in% tagsOfInterest) %>%
    select(tag_users_user_id) %>% 
    pull(tag_users_user_id)
  
  table <- studentsTable %>% 
    filter(students_id %in% userIds) %>%
    drop_na()
  names(table)[names(table) == 'students_id'] <- 'userId'
  return(table)
}
```


```{r}
# extractQuestionsOfInterests: User Defined Function to create a dataframe for questions and their rate(score) with tags of interests.

extractQuestionsOfInterests <- function(tagTable, questionTagTable, questionTable, questionScoreTable, interest) {
  tagsOfInterest <- extractTags(tagTable, interest)
  
  df <- questionTagTable %>% 
    filter(tag_questions_tag_id %in% tagsOfInterest)
  
  for (i in 1:length(interest)){
    df <- df %>%
      mutate('dummy' = ifelse(tag_questions_tag_id %in% tagsOfInterest[i],1,0))
    names(df)[names(df) == 'dummy'] <- interest[i]
  }
  
  df <- aggregate(. ~tag_questions_question_id, data=df, sum, na.rm=TRUE)
  
  questionIdVector <- df %>% 
    pull(tag_questions_question_id)
  
  table <- questionTable %>% filter(questions_id %in% questionIdVector)
  
  df <- df %>% select(-tag_questions_tag_id)
  print(df)
  
  names(df)[names(df) == 'tag_questions_question_id'] <- 'questions_id'
  table <- merge(table, df,by=c("questions_id"))
  
  names(table)[names(table) == 'questions_id'] <- 'id'
  total <- merge(table, questionScoreTable,by=c("id"))
  
  names(total)[names(total) == 'questions_author_id'] <- 'userId'
  return(total)
}
```


```{r}
interest <- c('teaching', 'teacher', 'education', 'high school', 'school')
usersOfInterests <- extractStudentsWithInterest(tags, tag_users, students, interest)
head(usersOfInterests)
```


```{r}
questionsOfInterests <- extractQuestionsOfInterests(tags, tag_questions, questions, questions_score, interest)
head(questionsOfInterests)
```



```{r}
# merge

combinedData <- merge(x = questionsOfInterests, y = usersOfInterests, by = "userId", all.X = TRUE)
combinedData
```


## Regression

```{r}
library(gbm)
gradientBoostFeatureImportanceForRegression <- function(data){
  mod_boost <- gbm(score ~ , distribution = "gaussian",
                     data = data, n.trees = 3000, interaction.depth = 2)
  mod_boost
  msummary(mod_boost)
}
gradientBoostFeatureImportanceForRegression(combinedData)
```


### Supervised


### TF-IDF Vectorization
```{r}
head(combinedData$questions_body)





it_data = itoken(questionsOfInterests$questions_body,
       preprocessor = tolower,
       tokenizer = word_tokenizer,
       ids = questionsOfInterests$id,
       progressbar = FALSE)

it_data

vocab = create_vocabulary(it_data)
vocab
```

```{r}
vectorizer = vocab_vectorizer(vocab)
dtm_data = create_dtm(it_data, vectorizer)


# Define Tf-idf Model
tfidf = TfIdf$new()
tfidf_data = fit_transform(dtm_data, tfidf)
```

```{r}
tfidf
vectors = transform(tfidf_data, tfidf)
vectors
```




```{r}

library(glmnet)
dtm_train = create_dtm(it_data, vectorizer)
NFOLDS = 4
t1 = Sys.time()
dtm_train

glmnet_classifier = cv.glmnet(x = dtm_train, y = combinedData$score, 
                              family = 'gaussian', 
                              # L1 penalty
                              alpha = 1,
                              # interested in the area under ROC curve
                              type.measure = "auc",
                              # 5-fold cross-validation
                              nfolds = NFOLDS,
                              # high value is less accurate, but has faster training
                              thresh = 1e-3,
                              # again lower number of iterations for faster training
                              maxit = 1e3)
print(difftime(Sys.time(), t1, units = 'sec'))
```






## Supervised Learning to predict score

### split
```{r}
n <- nrow(combinedData)
test_idx <- sample.int(n, size = round(0.20 * n))
train <- combinedData[-test_idx, ]
test <- combinedData[test_idx, ]
```

### linear model
```{r}
mod_logit <- glm(score ~ teacher + teaching + high + school + education, data = train, family = "gaussian")
logitProb <- predict(mod_logit, newdata = test, type = "response")
plot(logitProb)
test <- test %>%
  mutate(regression = logitProb)
```


### random forest
```{r}
mod_forest <- randomForest(score ~ teacher + teaching + high + school + education, data = train, ntree = 100, mtry = 2)
mod_forest <- predict(mod_forest, newdata = test, type = "response")
plot(mod_forest)
test <- test %>%
  mutate(forest = mod_forest)

```

# simple tree
```{r}
mod_tree <- rpart(score ~ teacher + teaching + high + school + education, data = train)
tree_pred <- predict(mod_tree, newdata = test, type = "vector")
plot(tree_pred)
test <- test %>%
  mutate(tree = tree_pred)
```




```{r}

resultTest <- test %>%
  select(regression, tree, forest, score) %>%
  mutate(regression_diff = (as.double(regression) - score) ** 2,
         tree_diff = (as.double(tree) - score) ** 2,
         forest_diff = (as.double(forest) - score) ** 2)

rmseRegression <- sqrt(mean(resultTest$regression_diff))
rmseTree <- sqrt(mean(resultTest$tree_diff))
rmseForest <- sqrt(mean(resultTest$forest_diff))

rmseRegression
rmseTree
rmseForest


```










